{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Y9IOSIgvNeBU",
        "vF7ZwfOKpdEw"
      ],
      "authorship_tag": "ABX9TyOxrNDjJn90lX2ihT5qh4YI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yenchunR/NLP_HW4/blob/master/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9IOSIgvNeBU"
      },
      "source": [
        "# Install Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQ_DqNfo0Wfd",
        "outputId": "06c0c97b-70ae-4638-9042-149d92eddc71"
      },
      "source": [
        "!pip3 install hanziconv"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hanziconv\n",
            "  Downloading hanziconv-0.3.2.tar.gz (276 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276 kB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: hanziconv\n",
            "  Building wheel for hanziconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hanziconv: filename=hanziconv-0.3.2-py2.py3-none-any.whl size=23225 sha256=51fb4f72de77b86b5812f5b76df9edda70e2e32c2f2d7d83c557d9b6e1a88ba5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e3/22/7bf50146a3ee95d1fdcbfabc44a1fe15b6e2ab7348ab7337bf\n",
            "Successfully built hanziconv\n",
            "Installing collected packages: hanziconv\n",
            "Successfully installed hanziconv-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlGwD3cYYAkF",
        "outputId": "682b9419-e37a-481d-9d68-056d52de5d10"
      },
      "source": [
        "!pip3 install gensim"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF7ZwfOKpdEw"
      },
      "source": [
        "# 將Colab連結Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D3f_ouRpj2B",
        "outputId": "3878f6f1-a892-44b6-c741-537655b9cd0e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kia8HbibsPxt"
      },
      "source": [
        "# 讀取所有檔案路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyrJilquqGK0",
        "outputId": "264b3d1d-f68f-4c29-c70b-68fbd9df24a0"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# 把列出資料夾的程式碼寫成一個函式\n",
        "filePath = []\n",
        "def show_folder_content(folder_path):\n",
        "\n",
        "    folder_content = os.listdir(folder_path)\n",
        "    for item in folder_content:\n",
        "        if os.path.isdir(folder_path + '/' + item):\n",
        "            # 呼叫自己處理這個子資料夾\n",
        "            show_folder_content(folder_path + '/' + item)\n",
        "        elif os.path.isfile(folder_path + '/' + item):\n",
        "            filePath.append(folder_path + '/' + item)\n",
        "        else:\n",
        "            print('無法辨識：' + item)\n",
        "\n",
        "\n",
        "# 顯示指定資料夾的內容\n",
        "target_folder = '/content/drive/My Drive/wiki_zh'\n",
        "show_folder_content(target_folder)\n",
        "print(\"Finish\", len(filePath))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish 1280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_br9dhQMzVdj"
      },
      "source": [
        "# jieba 斷詞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3Jcdxzzwger",
        "outputId": "51042a82-e730-41de-90f9-d18351be0ee4"
      },
      "source": [
        "# coding=utf-8\n",
        "import jieba \n",
        "import json\n",
        "import re\n",
        "\n",
        "# 讀取停用詞\n",
        "def stopwordslist(filepath):  \n",
        "    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]  \n",
        "    return stopwords \n",
        "\n",
        "def LoadToSeg(filepath, fW):\n",
        "    with open(filePath[0], 'r') as obj:\n",
        "        for line in obj.readlines():\n",
        "            dic = json.loads(line)\n",
        "            temp_text = re.findall('[\\u4e00-\\u9fa5]', dic['text'])\n",
        "            text = ''.join(temp_text)\n",
        "            tags = jieba.lcut(text, cut_all=False)\n",
        "            ThisLine = ''\n",
        "            for tag in tags:\n",
        "                if tag not in stopwords:  \n",
        "                    if tag != '\\t' and tag != '\\n' and tag != '' and len(tag) > 1:  \n",
        "                        ThisLine += tag  \n",
        "                        ThisLine += \" \"   #再次組合成【帶空格】的串\n",
        "            fW.write((ThisLine+\"\\n\").encode('utf-8'))\n",
        "            \n",
        "stopwords = stopwordslist('/content/drive/My Drive/wiki_zh/DriveUploader/cn_stopwords.txt')  # 這裏加載停用詞的路徑 \n",
        "fileSegWordDonePath ='/content/drive/My Drive/wiki_zh/DriveUploader/corpusSegDone.txt'\n",
        "with open(fileSegWordDonePath,'wb') as fW:\n",
        "    fW.truncate(0)\n",
        "    index = 0\n",
        "    for path in filePath:\n",
        "        LoadToSeg(path, fW)\n",
        "        index += 1\n",
        "        if index % 100 == 0:\n",
        "            print(index)\n",
        "\n",
        "print(\"Finish\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.013 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSDjMZmDNvbQ"
      },
      "source": [
        "# word2vec 轉成高維空間向量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmFlgeRENyJw",
        "outputId": "6496db6d-b8a9-4210-f0f5-611a671412a2"
      },
      "source": [
        "from gensim.models import word2vec\n",
        "# jieba分詞轉word2vec向量\n",
        "fileSegWordDonePath ='/content/drive/My Drive/wiki_zh/DriveUploader/corpusSegDone.txt'\n",
        "fileSegWordDonePath2 ='/content/drive/My Drive/wiki_zh/DriveUploader/corpusSegDone.model'\n",
        "\n",
        "sentences = word2vec.LineSentence(fileSegWordDonePath)\n",
        "model = word2vec.Word2Vec(sentences, size=250, min_count=5, negative=5, workers=3, sg=1, verbose = True)\n",
        "model.save(fileSegWordDonePath2)\n",
        "print(\"Finish\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8uhRbtlORPM"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG3wID4jRxH_"
      },
      "source": [
        "# -*- coding: utf-8 -*-# -*- coding: utf-8 -*-\n",
        "import sys\n",
        "from gensim.models import word2vec \n",
        "from gensim import models\n",
        "from hanziconv import HanziConv\n",
        "\n",
        "def main():   \n",
        "    a = input(\"input:\") \n",
        "    Simp = HanziConv.toSimplified(a)\n",
        "    model = models.Word2Vec.load(fileSegWordDonePath2)\n",
        "    try:\n",
        "        res = model.most_similar(Simp, topn=10)\n",
        "        for item in res: \n",
        "            print(HanziConv.toTraditional(item[0]) + ':' + str(item[1]))\n",
        "    except KeyError:\n",
        "        print(a + \" is not in the vocabulary\")\n",
        "\n",
        "if __name__=='__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}