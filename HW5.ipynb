{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrmr3omDthLHu/6YGVwGXc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yenchunR/NLP_HW4/blob/master/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SQRoPRi184S"
      },
      "source": [
        "# Import module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb3qOs32gUAW"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "from IPython.display import clear_output "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0gW8GfA5r1v"
      },
      "source": [
        "!pip3 uninstall tensorflow-gpu==2.0.0-beta0\n",
        "!pip3 uninstall -y tensorflow\n",
        "!pip3 uninstall keras\n",
        "clear_output()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwMdBxPM4AsD"
      },
      "source": [
        "!pip3 uninstall tensorflow-gpu==2.0.0-beta0\n",
        "!pip3 install tensorflow-gpu==2.0.0-beta0\n",
        "!pip3 uninstall tensorflow\n",
        "!pip3 install tensorflow\n",
        "clear_output()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwwtxGvN-NeQ"
      },
      "source": [
        "!pip3 uninstall tensorflow-datasets\n",
        "!pip3 install tensorflow-datasets\n",
        "clear_output()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2HZO9efBga7"
      },
      "source": [
        "!pip3 install --ignore-installed --upgrade --ignore-installed tensorflow\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSl4h07hBLxs",
        "outputId": "3b6d3a01-ba41-4aab-fe88-551e3379185d"
      },
      "source": [
        "!pip3 install tensorflow-gpu==2.0.0-beta0\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "clear_output()\n",
        "print(tf.__version__)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZqghoS6CT6q"
      },
      "source": [
        "!pip3 list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wkTG5C34G60"
      },
      "source": [
        "## 改變 logging 等級"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQFnj0994KEz"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=\"ERROR\")\n",
        "\n",
        "np.set_printoptions(suppress=True) #讓 numpy 不要顯示科學記號"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tykotz1DBqA"
      },
      "source": [
        "# 路徑變數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP5hwEf1DDOb"
      },
      "source": [
        "output_dir = \"nmt\"\n",
        "en_vocab_file = os.path.join(output_dir, \"en_vocab\")\n",
        "zh_vocab_file = os.path.join(output_dir, \"zh_vocab\")\n",
        "checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
        "log_dir = os.path.join(output_dir, 'logs')\n",
        "download_dir = \"tensorflow-datasets/downloads\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "  os.makedirs(output_dir)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCZeifuPDbbh"
      },
      "source": [
        "# 建立輸入管道"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxquHFw0Dcd8"
      },
      "source": [
        "## 下載並準備資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WfNNuu4DfCs",
        "outputId": "bcaadaca-1a55-4885-94d8-e1735add3ab6"
      },
      "source": [
        "tmp_builder = tfds.builder(\"wmt19_translate/zh-en\")\n",
        "pprint(tmp_builder.subsets)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{Split('train'): ['newscommentary_v14',\n",
            "                  'wikititles_v1',\n",
            "                  'uncorpus_v1',\n",
            "                  'casia2015',\n",
            "                  'casict2011',\n",
            "                  'casict2015',\n",
            "                  'datum2015',\n",
            "                  'datum2017',\n",
            "                  'neu2017'],\n",
            " Split('validation'): ['newstest2018']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fn3wHgiDmX4"
      },
      "source": [
        "## Download News Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNq-PPj4DqWO"
      },
      "source": [
        "config = tfds.translate.wmt.WmtConfig(\n",
        "    version=\"0.0.3\",\n",
        "    language_pair=(\"zh\", \"en\"),\n",
        "    subsets={\n",
        "        tfds.Split.TRAIN: [\"newscommentary_v14\"]\n",
        "    },\n",
        ")\n",
        "builder = tfds.builder(\"wmt_translate\", config=config)\n",
        "builder.download_and_prepare(download_dir=download_dir)\n",
        "clear_output()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vil8PpmWHJko"
      },
      "source": [
        "## 切割資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIYsVYZLHK4y",
        "outputId": "b754dab5-edbb-4e31-8d20-4fe1e77bb3d4"
      },
      "source": [
        "examples = builder.as_dataset(split=['train[:20%]','train[20%:21%]','train[21%:]'], as_supervised=True)\n",
        "\n",
        "train_examples, val_examples, _ = examples\n",
        "print(train_examples)\n",
        "print(val_examples)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>\n",
            "<PrefetchDataset shapes: ((), ()), types: (tf.string, tf.string)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCKhnpIFJyAR"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX9XwhHlJ2Nn",
        "outputId": "d6e8ae41-a6d2-49f8-bacc-840a372480e2"
      },
      "source": [
        "for en, zh in train_examples.take(3):\n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'The fear is real and visceral, and politicians ignore it at their peril.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe8\\xbf\\x99\\xe7\\xa7\\x8d\\xe6\\x81\\x90\\xe6\\x83\\xa7\\xe6\\x98\\xaf\\xe7\\x9c\\x9f\\xe5\\xae\\x9e\\xe8\\x80\\x8c\\xe5\\x86\\x85\\xe5\\x9c\\xa8\\xe7\\x9a\\x84\\xe3\\x80\\x82 \\xe5\\xbf\\xbd\\xe8\\xa7\\x86\\xe5\\xae\\x83\\xe7\\x9a\\x84\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xae\\xb6\\xe4\\xbb\\xac\\xe5\\x89\\x8d\\xe9\\x80\\x94\\xe5\\xa0\\xaa\\xe5\\xbf\\xa7\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word \\xe2\\x80\\x9cliberal\\xe2\\x80\\x9d \\xe2\\x80\\x93 a champion of the cause of individual freedom.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe4\\xba\\x8b\\xe5\\xae\\x9e\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe5\\xbe\\xb7\\xe5\\x9b\\xbd\\xe6\\x94\\xbf\\xe6\\xb2\\xbb\\xe5\\xb1\\x80\\xe5\\x8a\\xbf\\xe9\\x9c\\x80\\xe8\\xa6\\x81\\xe7\\x9a\\x84\\xe4\\xb8\\x8d\\xe8\\xbf\\x87\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe4\\xb8\\xaa\\xe7\\xac\\xa6\\xe5\\x90\\x88\\xe7\\xbe\\x8e\\xe5\\x9b\\xbd\\xe6\\x89\\x80\\xe8\\xb0\\x93\\xe2\\x80\\x9c\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe2\\x80\\x9d\\xe5\\xae\\x9a\\xe4\\xb9\\x89\\xe7\\x9a\\x84\\xe7\\x9c\\x9f\\xe6\\xad\\xa3\\xe7\\x9a\\x84\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe5\\x85\\x9a\\xe6\\xb4\\xbe\\xef\\xbc\\x8c\\xe4\\xb9\\x9f\\xe5\\xb0\\xb1\\xe6\\x98\\xaf\\xe4\\xb8\\xaa\\xe4\\xba\\xba\\xe8\\x87\\xaa\\xe7\\x94\\xb1\\xe4\\xba\\x8b\\xe4\\xb8\\x9a\\xe7\\x9a\\x84\\xe5\\x80\\xa1\\xe5\\xaf\\xbc\\xe8\\x80\\x85\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n",
            "tf.Tensor(b'Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.', shape=(), dtype=string)\n",
            "tf.Tensor(b'\\xe5\\xbf\\x85\\xe9\\xa1\\xbb\\xe4\\xbb\\x98\\xe5\\x87\\xba\\xe5\\xb7\\xa8\\xe5\\xa4\\xa7\\xe7\\x9a\\x84\\xe5\\x8a\\xaa\\xe5\\x8a\\x9b\\xe5\\x92\\x8c\\xe5\\x9f\\xba\\xe7\\xa1\\x80\\xe8\\xae\\xbe\\xe6\\x96\\xbd\\xe6\\x8a\\x95\\xe8\\xb5\\x84\\xe6\\x89\\x8d\\xe8\\x83\\xbd\\xe5\\xae\\x8c\\xe6\\x88\\x90\\xe5\\x90\\x91\\xe5\\x8f\\xaf\\xe5\\x86\\x8d\\xe7\\x94\\x9f\\xe8\\x83\\xbd\\xe6\\xba\\x90\\xe7\\x9a\\x84\\xe8\\xbf\\x87\\xe6\\xb8\\xa1\\xe3\\x80\\x82', shape=(), dtype=string)\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCTtEfPlJ99m"
      },
      "source": [
        "#### 利用 numpy() 取出並解碼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kilwBcHRJ_rp",
        "outputId": "90421eeb-6d75-492c-882a-eaf3b7fd533c"
      },
      "source": [
        "sample_examples = []\n",
        "num_samples = 10\n",
        "\n",
        "for en_t, zh_t in train_examples.take(num_samples):\n",
        "  en = en_t.numpy().decode(\"utf-8\")\n",
        "  zh = zh_t.numpy().decode(\"utf-8\")\n",
        "  \n",
        "  print(en)\n",
        "  print(zh)\n",
        "  print('-' * 10)\n",
        "  \n",
        "  # 之後用來簡單評估模型的訓練情況\n",
        "  sample_examples.append((en, zh))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The fear is real and visceral, and politicians ignore it at their peril.\n",
            "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
            "----------\n",
            "In fact, the German political landscape needs nothing more than a truly liberal party, in the US sense of the word “liberal” – a champion of the cause of individual freedom.\n",
            "事实上，德国政治局势需要的不过是一个符合美国所谓“自由”定义的真正的自由党派，也就是个人自由事业的倡导者。\n",
            "----------\n",
            "Shifting to renewable-energy sources will require enormous effort and major infrastructure investment.\n",
            "必须付出巨大的努力和基础设施投资才能完成向可再生能源的过渡。\n",
            "----------\n",
            "In this sense, it is critical to recognize the fundamental difference between “urban villages” and their rural counterparts.\n",
            "在这方面，关键在于认识到“城市村落”和农村村落之间的根本区别。\n",
            "----------\n",
            "A strong European voice, such as Nicolas Sarkozy’s during the French presidency of the EU, may make a difference, but only for six months, and at the cost of reinforcing other European countries’ nationalist feelings in reaction to the expression of “Gallic pride.”\n",
            "法国担任轮值主席国期间尼古拉·萨科奇统一的欧洲声音可能让人耳目一新，但这种声音却只持续了短短六个月，而且付出了让其他欧洲国家在面对“高卢人的骄傲”时民族主义情感进一步被激发的代价。\n",
            "----------\n",
            "Most of Japan’s bondholders are nationals (if not the central bank) and have an interest in political stability.\n",
            "日本债券持有人大多为本国国民（甚至中央银行 ） ， 政治稳定符合他们的利益。\n",
            "----------\n",
            "Paul Romer, one of the originators of new growth theory, has accused some leading names, including the Nobel laureate Robert Lucas, of what he calls “mathiness” – using math to obfuscate rather than clarify.\n",
            "新增长理论创始人之一的保罗·罗默（Paul Romer）也批评一些著名经济学家，包括诺贝尔奖获得者罗伯特·卢卡斯（Robert Lucas）在内，说他们“数学性 ” （ 罗默的用语）太重，结果是让问题变得更加模糊而不是更加清晰。\n",
            "----------\n",
            "It is, in fact, a capsule depiction of the United States Federal Reserve and the European Central Bank.\n",
            "事实上，这就是对美联储和欧洲央行的简略描述。\n",
            "----------\n",
            "Given these variables, the degree to which migration is affected by asylum-seekers will not be easy to predict or control.\n",
            "考虑到这些变量，移民受寻求庇护者的影响程度很难预测或控制。\n",
            "----------\n",
            "WASHINGTON, DC – In the 2016 American presidential election, Hillary Clinton and Donald Trump agreed that the US economy is suffering from dilapidated infrastructure, and both called for greater investment in renovating and upgrading the country’s public capital stock.\n",
            "华盛顿—在2016年美国总统选举中，希拉里·克林顿和唐纳德·特朗普都认为美国经济饱受基础设施陈旧的拖累，两人都要求加大投资用于修缮和升级美国公共资本存量。\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb9yS6YXKFsi"
      },
      "source": [
        "# 建立中文與英文字典"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y61Uw0XuKI3x"
      },
      "source": [
        "## 為英文語料建立字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqjJkMAiKKEG",
        "outputId": "43f2b9f1-93d9-48f9-9730-be9a890a1cc6"
      },
      "source": [
        "## load_from_file 函式嘗試讀取之前已經建好的字典檔案\n",
        "\n",
        "%%time\n",
        "try:\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.load_from_file(en_vocab_file)\n",
        "  print(f\"載入已建立的字典： {en_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (en.numpy() for en, _ in train_examples), \n",
        "      target_vocab_size=2**13) # 有需要可以調整字典大小\n",
        "  \n",
        "  # 將字典檔案存下以方便下次 warmstart\n",
        "  subword_encoder_en.save_to_file(en_vocab_file)\n",
        "  \n",
        "\n",
        "print(f\"字典大小：{subword_encoder_en.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_en.subwords[:10]}\")\n",
        "print()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "沒有已建立的字典，從頭建立。\n",
            "字典大小：8113\n",
            "前 10 個 subwords：[', ', 'the_', 'of_', 'to_', 'and_', 's_', 'in_', 'a_', 'is_', 'that_']\n",
            "\n",
            "CPU times: user 1min 32s, sys: 3.34 s, total: 1min 35s\n",
            "Wall time: 1min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-b4mWqhME1H"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ywSl8pMMD-"
      },
      "source": [
        "#### 用該字典來幫我們將一個英文句子轉成對應的索引序列（index sequence）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAI941N7MNug",
        "outputId": "a2c3df7c-3e15-4a5a-c086-ff7ed70565b5"
      },
      "source": [
        "sample_string = 'Taiwan is beautiful.'\n",
        "indices = subword_encoder_en.encode(sample_string)\n",
        "indices"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3461, 7889, 9, 3502, 4379, 1134, 7903]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boYStc5OMSmB"
      },
      "source": [
        "#### 將這些索引還原"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJtUqVFtMToE",
        "outputId": "9009b6f3-1750-410d-a0ba-44f36c1973d5"
      },
      "source": [
        "print(\"{0:10}{1:6}\".format(\"Index\", \"Subword\"))\n",
        "print(\"-\" * 15)\n",
        "for idx in indices:\n",
        "  subword = subword_encoder_en.decode([idx])\n",
        "  print('{0:5}{1:6}'.format(idx, ' ' * 5 + subword))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index     Subword\n",
            "---------------\n",
            " 3461     Taiwan\n",
            " 7889      \n",
            "    9     is \n",
            " 3502     bea\n",
            " 4379     uti\n",
            " 1134     ful\n",
            " 7903     .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HWJJUP-Mc_p"
      },
      "source": [
        "#### 編碼與解碼是 2 個完全可逆"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3yxRXv_MeiH",
        "outputId": "e45e8628-a031-4f06-dbb5-0ee3c30630b8"
      },
      "source": [
        "sample_string = 'Taiwan is beautiful.'\n",
        "indices = subword_encoder_en.encode(sample_string)\n",
        "decoded_string = subword_encoder_en.decode(indices)\n",
        "assert decoded_string == sample_string\n",
        "pprint((sample_string, decoded_string))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Taiwan is beautiful.', 'Taiwan is beautiful.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgGBuP5AMlHo"
      },
      "source": [
        "## 為中文建立一個字典"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpTrJyz2MqYO",
        "outputId": "99813096-ef13-4147-ac30-6e0104057ef1"
      },
      "source": [
        "#https://www.tensorflow.org/datasets/api_docs/python/tfds/deprecated/text/SubwordTextEncoder\n",
        "\n",
        "%%time\n",
        "try:\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.load_from_file(zh_vocab_file)\n",
        "  print(f\"載入已建立的字典： {zh_vocab_file}\")\n",
        "except:\n",
        "  print(\"沒有已建立的字典，從頭建立。\")\n",
        "  subword_encoder_zh = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "      (zh.numpy() for _, zh in train_examples), \n",
        "      target_vocab_size=2**13, # 有需要可以調整字典大小\n",
        "      max_subword_length=1) # 每一個中文字就是字典裡的一個單位\n",
        "  \n",
        "  # 將字典檔案存下以方便下次 warmstart \n",
        "  subword_encoder_zh.save_to_file(zh_vocab_file)\n",
        "\n",
        "print(f\"字典大小：{subword_encoder_zh.vocab_size}\")\n",
        "print(f\"前 10 個 subwords：{subword_encoder_zh.subwords[:10]}\")\n",
        "print()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "沒有已建立的字典，從頭建立。\n",
            "字典大小：4205\n",
            "前 10 個 subwords：['的', '，', '。', '国', '在', '是', '一', '和', '不', '这']\n",
            "\n",
            "CPU times: user 8min 44s, sys: 2.46 s, total: 8min 46s\n",
            "Wall time: 8min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCkh5QrWPE31"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMR6lEPfPHKp"
      },
      "source": [
        "#### Test Chinese Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSYuDXHvPNKi",
        "outputId": "fb9b20c4-095e-4efd-d938-a9cbc3a50e3a"
      },
      "source": [
        "sample_string = sample_examples[0][1]\n",
        "indices = subword_encoder_zh.encode(sample_string)\n",
        "print(sample_string)\n",
        "print(indices)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "这种恐惧是真实而内在的。 忽视它的政治家们前途堪忧。\n",
            "[10, 151, 574, 1298, 6, 374, 55, 29, 193, 5, 1, 3, 3981, 931, 431, 125, 1, 17, 124, 33, 20, 97, 1089, 1247, 861, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVTQFS9bPQ2F"
      },
      "source": [
        "### Test 包含同語義的中英平行句子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXFznyQPPePN",
        "outputId": "bb415c8c-ae9b-4fa8-a8d9-ca1c81decf9c"
      },
      "source": [
        "en = \"The eurozone’s collapse forces a major realignment of European politics.\"\n",
        "zh = \"欧元区的瓦解强迫欧洲政治进行一次重大改组。\"\n",
        "\n",
        "# 將文字轉成為 subword indices\n",
        "en_indices = subword_encoder_en.encode(en)\n",
        "zh_indices = subword_encoder_zh.encode(zh)\n",
        "\n",
        "print(\"[英中原文]（轉換前）\")\n",
        "print(en)\n",
        "print(zh)\n",
        "print()\n",
        "print('-' * 20)\n",
        "print()\n",
        "print(\"[英中序列]（轉換後）\")\n",
        "print(en_indices)\n",
        "print(zh_indices)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[英中原文]（轉換前）\n",
            "The eurozone’s collapse forces a major realignment of European politics.\n",
            "欧元区的瓦解强迫欧洲政治进行一次重大改组。\n",
            "\n",
            "--------------------\n",
            "\n",
            "[英中序列]（轉換後）\n",
            "[16, 900, 11, 6, 1527, 874, 8, 230, 2259, 2728, 239, 3, 89, 1236, 7903]\n",
            "[44, 202, 168, 1, 852, 201, 231, 592, 44, 87, 17, 124, 106, 38, 7, 279, 86, 18, 212, 265, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDPbQuAgPjso"
      },
      "source": [
        "# 前處理數據"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQa3FZg5P81v"
      },
      "source": [
        "## 在一個序列的前後各加入一個特殊的 token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtNQJWinQDKQ"
      },
      "source": [
        "def encode(en_t, zh_t):\n",
        "  # 因為字典的索引從 0 開始，\n",
        "  # 我們可以使用 subword_encoder_en.vocab_size 這個值作為 BOS 的索引值\n",
        "  # 用 subword_encoder_en.vocab_size + 1 作為 EOS 的索引值\n",
        "  en_indices = [subword_encoder_en.vocab_size] + subword_encoder_en.encode(\n",
        "      en_t.numpy()) + [subword_encoder_en.vocab_size + 1]\n",
        "  # 同理，不過是使用中文字典的最後一個索引 + 1\n",
        "  zh_indices = [subword_encoder_zh.vocab_size] + subword_encoder_zh.encode(\n",
        "      zh_t.numpy()) + [subword_encoder_zh.vocab_size + 1]\n",
        "  \n",
        "  return en_indices, zh_indices"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSNWa-5kQHz0"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcfcNE0jQKR9"
      },
      "source": [
        "en_t, zh_t = next(iter(train_examples))\n",
        "en_indices, zh_indices = encode(en_t, zh_t)\n",
        "print('英文 BOS 的 index：', subword_encoder_en.vocab_size)\n",
        "print('英文 EOS 的 index：', subword_encoder_en.vocab_size + 1)\n",
        "print('中文 BOS 的 index：', subword_encoder_zh.vocab_size)\n",
        "print('中文 EOS 的 index：', subword_encoder_zh.vocab_size + 1)\n",
        "\n",
        "print('\\n輸入為 2 個 Tensors：')\n",
        "pprint((en_t, zh_t))\n",
        "print('-' * 15)\n",
        "print('輸出為 2 個索引序列：')\n",
        "pprint((en_indices, zh_indices))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41KL-v8hQgO6"
      },
      "source": [
        "## 將剛剛定義的 encode 函式包成一個以 eager 模式執行的 TensorFlow Op"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQrLL6G8QjgQ",
        "outputId": "40f38bb1-e055-4d90-a9ab-65db82c3998a"
      },
      "source": [
        "def tf_encode(en_t, zh_t):\n",
        "  # 在 `tf_encode` 函式裡頭的 `en_t` 與 `zh_t` 都不是 Eager Tensors\n",
        "  # 要到 `tf.py_funtion` 裡頭才是\n",
        "  # 另外因為索引都是整數，所以使用 `tf.int64`\n",
        "  return tf.py_function(encode, [en_t, zh_t], [tf.int64, tf.int64])\n",
        "\n",
        "# `tmp_dataset` 為說明用資料集，說明完所有重要的 func，\n",
        "# 我們會從頭建立一個正式的 `train_dataset`\n",
        "tmp_dataset = train_examples.map(tf_encode)\n",
        "en_indices, zh_indices = next(iter(tmp_dataset))\n",
        "print(en_indices)\n",
        "print(zh_indices)\n",
        "## tmp_dataset 的輸出已經是兩個索引序列，而非原文字串"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[8113   16 1284    9  243    5 1275 1756  156    1    5 1016 5566   21\n",
            "   38   33 2982 7965 7903 8114], shape=(20,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[4205   10  151  574 1298    6  374   55   29  193    5    1    3 3981\n",
            "  931  431  125    1   17  124   33   20   97 1089 1247  861    3 4206], shape=(28,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JM2wNwcQu0J"
      },
      "source": [
        "## 將長度超過 40 個 tokens 的序列都去掉"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8sdrrkYQvwZ"
      },
      "source": [
        "MAX_LENGTH = 40\n",
        "\n",
        "def filter_max_length(en, zh, max_length=MAX_LENGTH):\n",
        "  # en, zh 分別代表英文與中文的索引序列\n",
        "  return tf.logical_and(tf.size(en) <= max_length,\n",
        "                        tf.size(zh) <= max_length)\n",
        "\n",
        "# tf.data.Dataset.filter(func) 只會回傳 func 為真的例子\n",
        "tmp_dataset = tmp_dataset.filter(filter_max_length)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFBUMLp1Q1mQ"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV-CyPN_Q3Uz",
        "outputId": "83ebb3ba-4657-4d62-ca86-7a2681e73ac5"
      },
      "source": [
        "# 因為我們數據量小可以這樣 count\n",
        "num_examples = 0\n",
        "for en_indices, zh_indices in tmp_dataset:\n",
        "  cond1 = len(en_indices) <= MAX_LENGTH\n",
        "  cond2 = len(zh_indices) <= MAX_LENGTH\n",
        "  assert cond1 and cond2\n",
        "  num_examples += 1\n",
        "\n",
        "print(f\"所有英文與中文序列長度都不超過 {MAX_LENGTH} 個 tokens\")\n",
        "print(f\"訓練資料集裡總共有 {num_examples} 筆數據\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "所有英文與中文序列長度都不超過 40 個 tokens\n",
            "訓練資料集裡總共有 29784 筆數據\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkV4l7nXR2IU"
      },
      "source": [
        "## 將 batch 裡的所有序列都 pad 到同樣長度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5NxSlHVR4qJ",
        "outputId": "c83f1cca-54ec-42e4-8e80-da490ca878dd"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "# 將 batch 裡的所有序列都 pad 到同樣長度\n",
        "tmp_dataset = tmp_dataset.padded_batch(BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
        "en_batch, zh_batch = next(iter(tmp_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113   16 1284 ...    0    0    0]\n",
            " [8113 1894 1302 ...    0    0    0]\n",
            " [8113   44   40 ...    0    0    0]\n",
            " ...\n",
            " [8113  122  506 ...    0    0    0]\n",
            " [8113   16  215 ...    0    0    0]\n",
            " [8113 7443 7889 ...    0    0    0]], shape=(64, 39), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205   10  151 ...    0    0    0]\n",
            " [4205  206  275 ...    0    0    0]\n",
            " [4205    5   10 ...    0    0    0]\n",
            " ...\n",
            " [4205   34    6 ...    0    0    0]\n",
            " [4205  317  256 ...    0    0    0]\n",
            " [4205  167  326 ...    0    0    0]], shape=(64, 40), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zdu_fZVSFSr"
      },
      "source": [
        "## 從頭建立訓練集與驗證集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2NnmHPUSGRg"
      },
      "source": [
        "# 訓練集\n",
        "train_dataset = (train_examples  # 輸出：(英文句子, 中文句子)\n",
        "                 .map(tf_encode) # 輸出：(英文索引序列, 中文索引序列)\n",
        "                 .filter(filter_max_length) # 同上，且序列長度都不超過 40\n",
        "                 .cache() # 加快讀取數據\n",
        "                 .shuffle(BUFFER_SIZE) # 將例子洗牌確保隨機性\n",
        "                 .padded_batch(BATCH_SIZE, # 將 batch 裡的序列都 pad 到一樣長度\n",
        "                               padded_shapes=([-1], [-1]))\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE)) # 加速\n",
        "# 驗證集\n",
        "val_dataset = (val_examples\n",
        "               .map(tf_encode)\n",
        "               .filter(filter_max_length)\n",
        "               .padded_batch(BATCH_SIZE, \n",
        "                             padded_shapes=([-1], [-1])))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCgpANKnSKZ5"
      },
      "source": [
        "### Print Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMgLD7urSMKZ",
        "outputId": "81ed4b7f-eeb0-4172-fe12-ad76cdd35773"
      },
      "source": [
        "en_batch, zh_batch = next(iter(train_dataset))\n",
        "print(\"英文索引序列的 batch\")\n",
        "print(en_batch)\n",
        "print('-' * 20)\n",
        "print(\"中文索引序列的 batch\")\n",
        "print(zh_batch)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "英文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[8113   87    9 ...    0    0    0]\n",
            " [8113  537   27 ...    0    0    0]\n",
            " [8113   16 1725 ...    0    0    0]\n",
            " ...\n",
            " [8113   44    8 ...    0    0    0]\n",
            " [8113  103    9 ...    0    0    0]\n",
            " [8113  367  693 ...    0    0    0]], shape=(128, 38), dtype=int64)\n",
            "--------------------\n",
            "中文索引序列的 batch\n",
            "tf.Tensor(\n",
            "[[4205   10   69 ...    0    0    0]\n",
            " [4205   32   51 ...    0    0    0]\n",
            " [4205   29  422 ...    0    0    0]\n",
            " ...\n",
            " [4205    5    7 ...    0    0    0]\n",
            " [4205   65    1 ...    0    0    0]\n",
            " [4205    7   28 ... 4206    0    0]], shape=(128, 40), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbNy3JYUcFcX"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKjlfNblcmaO"
      },
      "source": [
        "## 建立兩個要拿來持續追蹤的中英平行句子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NptxGN4jco61",
        "outputId": "08f9f0ac-70d3-4921-ca97-f6d6dc6921ff"
      },
      "source": [
        "demo_examples = [\n",
        "    (\"It is important.\", \"这很重要。\"),\n",
        "    (\"The numbers speak for themselves.\", \"数字证明了一切。\"),\n",
        "]\n",
        "pprint(demo_examples)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('It is important.', '这很重要。'),\n",
            " ('The numbers speak for themselves.', '数字证明了一切。')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1ykaLdicwxG",
        "outputId": "df0bf577-540a-41ce-e362-37da78fbaef2"
      },
      "source": [
        "batch_size = 2\n",
        "demo_examples = tf.data.Dataset.from_tensor_slices((\n",
        "    [en for en, _ in demo_examples], [zh for _, zh in demo_examples]\n",
        "))\n",
        "\n",
        "# 將兩個句子透過之前定義的字典轉換成子詞的序列（sequence of subwords）\n",
        "# 並添加 padding token: <pad> 來確保 batch 裡的句子有一樣長度\n",
        "demo_dataset = demo_examples.map(tf_encode)\\\n",
        "  .padded_batch(batch_size, padded_shapes=([-1], [-1]))\n",
        "\n",
        "# 取出這個 demo dataset 裡唯一一個 batch\n",
        "inp, tar = next(iter(demo_dataset))\n",
        "print('inp:', inp)\n",
        "print('' * 10)\n",
        "print('tar:', tar)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "\n",
            "tar: tf.Tensor(\n",
            "[[4205   10  241   86   27    3 4206    0    0    0]\n",
            " [4205  165  489  398  191   14    7  560    3 4206]], shape=(2, 10), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfPs7p6Sc4xt"
      },
      "source": [
        "## 視覺化 3 維詞嵌入張量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAjg7lp0c5nW"
      },
      "source": [
        "# + 2 是因為我們額外加了 <start> 以及 <end> tokens\n",
        "vocab_size_en = subword_encoder_en.vocab_size + 2\n",
        "vocab_size_zh = subword_encoder_zh.vocab_size + 2\n",
        "\n",
        "# 為了方便 demo, 將詞彙轉換到一個 4 維的詞嵌入空間\n",
        "d_model = 4\n",
        "embedding_layer_en = tf.keras.layers.Embedding(vocab_size_en, d_model)\n",
        "embedding_layer_zh = tf.keras.layers.Embedding(vocab_size_zh, d_model)\n",
        "\n",
        "emb_inp = embedding_layer_en(inp)\n",
        "emb_tar = embedding_layer_zh(tar)\n",
        "emb_inp, emb_tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq7k9DTjdAyZ",
        "outputId": "bc6b2242-e6a1-4034-e0ec-adb74f3ef231"
      },
      "source": [
        "print(\"tar[0]:\", tar[0][-3:])\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_tar[0]:\", emb_tar[0][-3:])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar[0]: tf.Tensor([0 0 0], shape=(3,), dtype=int64)\n",
            "--------------------\n",
            "emb_tar[0]: tf.Tensor(\n",
            "[[ 0.00907972 -0.04887122  0.04222881 -0.04204635]\n",
            " [ 0.00907972 -0.04887122  0.04222881 -0.04204635]\n",
            " [ 0.00907972 -0.04887122  0.04222881 -0.04204635]], shape=(3, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnkXx4WhdIPm"
      },
      "source": [
        "## 遮罩（masking)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNefSfL0dNVY"
      },
      "source": [
        "padding mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rEEa0ovdJ8N"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "inp_mask = create_padding_mask(inp)\n",
        "inp_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEj89lLSdR0b",
        "outputId": "eb1e9c79-70d1-4a46-9363-af53a8edb91a"
      },
      "source": [
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"tf.squeeze(inp_mask):\", tf.squeeze(inp_mask))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "tf.squeeze(inp_mask): tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(2, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKTv9pZFdXQp"
      },
      "source": [
        "## Scaled dot product attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q18lkFMpdYM6",
        "outputId": "f8116613-1131-4bea-b851-db7592624e56"
      },
      "source": [
        "# 設定一個 seed 確保我們每次都拿到一樣的隨機結果\n",
        "tf.random.set_seed(9527)\n",
        "\n",
        "# 自注意力機制：查詢 `q` 跟鍵值 `k` 都是 `emb_inp`\n",
        "q = emb_inp\n",
        "k = emb_inp\n",
        "# 簡單產生一個跟 `emb_inp` 同樣 shape 的 binary vector\n",
        "v = tf.cast(tf.math.greater(tf.random.uniform(shape=emb_inp.shape), 0.5), tf.float32)\n",
        "v"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 8, 4), dtype=float32, numpy=\n",
              "array([[[1., 0., 0., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 0., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [0., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.]],\n",
              "\n",
              "       [[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [1., 0., 0., 0.],\n",
              "        [1., 0., 1., 0.],\n",
              "        [0., 1., 0., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vqOLBAfdphx"
      },
      "source": [
        " scaled dot product attention 在 TensorFlow 裡是怎麼被實作"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z0fkIQ8duVo"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  # 將 `q`、 `k` 做點積再 scale\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)  # 取得 seq_k 的序列長度\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)  # scale by sqrt(dk)\n",
        "\n",
        "  # 將遮罩「加」到被丟入 softmax 前的 logits\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "  # 取 softmax 是為了得到總和為 1 的比例之後對 `v` 做加權平均\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # 以注意權重對 v 做加權平均（weighted average）\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-W_pRoYdjtY"
      },
      "source": [
        "假設沒有遮罩的存在"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iQrYZlZdlyE"
      },
      "source": [
        "mask = None\n",
        "output, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"output:\", output)\n",
        "print(\"-\" * 20)\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQZ_qp-xeLu7"
      },
      "source": [
        "為何遮罩要放在 softmax 之前而不能放之後？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLKUCzMnec8F",
        "outputId": "c67c7be4-8b33-4ad5-90ba-985d5c9a8fbc"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  # padding mask 的工作就是把索引序列中為 0 的位置設為 1\n",
        "  mask = tf.cast(tf.equal(seq, 0), tf.float32)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :] #　broadcasting\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "inp_mask = create_padding_mask(inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_mask:\", inp_mask)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inp: tf.Tensor(\n",
            "[[8113  103    9 1066 7903 8114    0    0]\n",
            " [8113   16 4111 6735   12 2750 7903 8114]], shape=(2, 8), dtype=int64)\n",
            "--------------------\n",
            "inp_mask: tf.Tensor(\n",
            "[[[[0. 0. 0. 0. 0. 0. 1. 1.]]]\n",
            "\n",
            "\n",
            " [[[0. 0. 0. 0. 0. 0. 0. 0.]]]], shape=(2, 1, 1, 8), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rStJGcnAemZd"
      },
      "source": [
        "# 這次讓我們將 padding mask 放入注意函式並觀察\n",
        "# 注意權重的變化\n",
        "mask = tf.squeeze(inp_mask, axis=1) # (batch_size, 1, seq_len_q)\n",
        "_, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MN9XggeeseW",
        "outputId": "02e77fe1-06b6-46e4-ad23-36185fd328f4"
      },
      "source": [
        "# 事實上也不完全是上句話的翻譯，\n",
        "# 因為我們在第一個維度還是把兩個句子都拿出來方便你比較\n",
        "attention_weights[:, :, -2:]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 8, 2), dtype=float32, numpy=\n",
              "array([[[0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ],\n",
              "        [0.        , 0.        ]],\n",
              "\n",
              "       [[0.12490132, 0.12504494],\n",
              "        [0.12476712, 0.12510008],\n",
              "        [0.12491203, 0.12503041],\n",
              "        [0.12505203, 0.12499987],\n",
              "        [0.12501954, 0.12502089],\n",
              "        [0.1248702 , 0.12507859],\n",
              "        [0.12517092, 0.12492557],\n",
              "        [0.12482853, 0.12509802]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDslo8oZewLN"
      },
      "source": [
        "第一個英文句子的最後 2 個位置因為是 <pad> 所以被遮罩「蓋住」而沒有權重值（上方 2 維陣列）；第二個句子的序列（下方 2 維陣列）則因為最後 2 個位置仍是正常的英文子詞，因此都有被其他子詞關注。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y469uqse0CF"
      },
      "source": [
        "look ahead mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLSwx1Mbe09G",
        "outputId": "e46d0d79-4395-47cb-8022-8363914ffa0a"
      },
      "source": [
        "# 建立一個 2 維矩陣，維度為 (size, size)，\n",
        "# 其遮罩為一個右上角的三角形\n",
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)\n",
        "\n",
        "seq_len = emb_tar.shape[1] # 注意這次我們用中文的詞嵌入張量 `emb_tar`\n",
        "look_ahead_mask = create_look_ahead_mask(seq_len)\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask\", look_ahead_mask)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_tar: tf.Tensor(\n",
            "[[[ 0.0375659  -0.04615805 -0.00253155 -0.0399281 ]\n",
            "  [ 0.03981594  0.02751767  0.03640976 -0.01245576]\n",
            "  [ 0.00901566 -0.01924636 -0.03085299 -0.02475961]\n",
            "  [-0.00019071 -0.00060445 -0.00113666  0.0467955 ]\n",
            "  [-0.0049249   0.01819317  0.01672241 -0.02736445]\n",
            "  [ 0.01253298 -0.04846127 -0.04290601 -0.03638048]\n",
            "  [ 0.00354321  0.00145434  0.03145135 -0.00397706]\n",
            "  [ 0.00907972 -0.04887122  0.04222881 -0.04204635]\n",
            "  [ 0.00907972 -0.04887122  0.04222881 -0.04204635]\n",
            "  [ 0.00907972 -0.04887122  0.04222881 -0.04204635]]\n",
            "\n",
            " [[ 0.0375659  -0.04615805 -0.00253155 -0.0399281 ]\n",
            "  [ 0.02098092 -0.01137238 -0.02203014 -0.0173551 ]\n",
            "  [-0.00692173 -0.00780449  0.01403377  0.0173481 ]\n",
            "  [ 0.03818235 -0.04620504  0.02387972 -0.01259404]\n",
            "  [-0.03889569  0.00619445  0.0203965   0.00359667]\n",
            "  [ 0.04817537 -0.01822008  0.01663016 -0.00169324]\n",
            "  [-0.00819866 -0.04908399 -0.01286504  0.01325971]\n",
            "  [ 0.03571085 -0.04145273 -0.01973292 -0.00493192]\n",
            "  [ 0.01253298 -0.04846127 -0.04290601 -0.03638048]\n",
            "  [ 0.00354321  0.00145434  0.03145135 -0.00397706]]], shape=(2, 10, 4), dtype=float32)\n",
            "--------------------\n",
            "look_ahead_mask tf.Tensor(\n",
            "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(10, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgS2IzV5e74e"
      },
      "source": [
        "# 讓我們用目標語言（中文）的 batch\n",
        "# 來模擬 Decoder 處理的情況\n",
        "temp_q = temp_k = emb_tar\n",
        "temp_v = tf.cast(tf.math.greater(\n",
        "    tf.random.uniform(shape=emb_tar.shape), 0.5), tf.float32)\n",
        "\n",
        "# 將 look_ahead_mask 放入注意函式\n",
        "_, attention_weights = scaled_dot_product_attention(\n",
        "    temp_q, temp_k, temp_v, look_ahead_mask)\n",
        "\n",
        "print(\"attention_weights:\", attention_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4g3RQx2fBA0",
        "outputId": "935b7c0a-4a19-4eb0-86cb-44c74be69397"
      },
      "source": [
        "attention_weights[:, 0, :]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTJOfse-fJ2I"
      },
      "source": [
        "## Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ATr1z1ZfYLV"
      },
      "source": [
        "### 先把一個 head 變成多個 heads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCf7cIw3fKzU"
      },
      "source": [
        "def split_heads(x, d_model, num_heads):\n",
        "  # x.shape: (batch_size, seq_len, d_model)\n",
        "  batch_size = tf.shape(x)[0]\n",
        "  \n",
        "  # 我們要確保維度 `d_model` 可以被平分成 `num_heads` 個 `depth` 維度\n",
        "  assert d_model % num_heads == 0\n",
        "  depth = d_model // num_heads  # 這是分成多頭以後每個向量的維度 \n",
        "  \n",
        "  # 將最後一個 d_model 維度分成 num_heads 個 depth 維度。\n",
        "  # 最後一個維度變成兩個維度，張量 x 從 3 維到 4 維\n",
        "  # (batch_size, seq_len, num_heads, depth)\n",
        "  reshaped_x = tf.reshape(x, shape=(batch_size, -1, num_heads, depth))\n",
        "  \n",
        "  # 將 head 的維度拉前使得最後兩個維度為子詞以及其對應的 depth 向量\n",
        "  # (batch_size, num_heads, seq_len, depth)\n",
        "  output = tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
        "  \n",
        "  return output\n",
        "\n",
        "# 我們的 `emb_inp` 裡頭的子詞本來就是 4 維的詞嵌入向量\n",
        "d_model = 4\n",
        "# 將 4 維詞嵌入向量分為 2 個 head 的 2 維矩陣\n",
        "num_heads = 2\n",
        "x = emb_inp\n",
        "\n",
        "output = split_heads(x, d_model, num_heads)  \n",
        "print(\"x:\", x)\n",
        "print(\"output:\", output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXJjjqAWfiRT"
      },
      "source": [
        "### multi-head attention 的實現"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1IzVwO8fjpK"
      },
      "source": [
        "# 實作一個執行多頭注意力機制的 keras layer\n",
        "# 在初始的時候指定輸出維度 `d_model` & `num_heads，\n",
        "# 在呼叫的時候輸入 `v`, `k`, `q` 以及 `mask`\n",
        "# 輸出跟 scaled_dot_product_attention 函式一樣有兩個：\n",
        "# output.shape            == (batch_size, seq_len_q, d_model)\n",
        "# attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  # 在初始的時候建立一些必要參數\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads # 指定要將 `d_model` 拆成幾個 heads\n",
        "    self.d_model = d_model # 在 split_heads 之前的基底維度\n",
        "    \n",
        "    assert d_model % self.num_heads == 0  # 前面看過，要確保可以平分\n",
        "    \n",
        "    self.depth = d_model // self.num_heads  # 每個 head 裡子詞的新的 repr. 維度\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)  # 分別給 q, k, v 的 3 個線性轉換 \n",
        "    self.wk = tf.keras.layers.Dense(d_model)  # 注意我們並沒有指定 activation func\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)  # 多 heads 串接後通過的線性轉換\n",
        "  \n",
        "  # 這跟我們前面看過的函式有 87% 相似\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "  \n",
        "  # multi-head attention 的實際執行流程，注意參數順序（這邊跟論文以及 TensorFlow 官方教學一致）\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    # 將輸入的 q, k, v 都各自做一次線性轉換到 `d_model` 維空間\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    # 前面看過的，將最後一個 `d_model` 維度分成 `num_heads` 個 `depth` 維度\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # 利用 broadcasting 讓每個句子的每個 head 的 qi, ki, vi 都各自進行注意力機制\n",
        "    # 輸出會多一個 head 維度\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    \n",
        "    # 跟我們在 `split_heads` 函式做的事情剛好相反，先做 transpose 再做 reshape\n",
        "    # 將 `num_heads` 個 `depth` 維度串接回原來的 `d_model` 維度\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "    # (batch_size, seq_len_q, num_heads, depth)\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model)) \n",
        "    # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    # 通過最後一個線性轉換\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuZnQELqfzMr"
      },
      "source": [
        "# emb_inp.shape == (batch_size, seq_len, d_model)\n",
        "#               == (2, 8, 4)\n",
        "assert d_model == emb_inp.shape[-1]  == 4\n",
        "num_heads = 2\n",
        "\n",
        "print(f\"d_model: {d_model}\")\n",
        "print(f\"num_heads: {num_heads}\\n\")\n",
        "\n",
        "# 初始化一個 multi-head attention layer\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "# 簡單將 v, k, q 都設置為 `emb_inp`\n",
        "# 順便看看 padding mask 的作用。\n",
        "# 別忘記，第一個英文序列的最後兩個 tokens 是 <pad>\n",
        "v = k = q = emb_inp\n",
        "padding_mask = create_padding_mask(inp)\n",
        "print(\"q.shape:\", q.shape)\n",
        "print(\"k.shape:\", k.shape)\n",
        "print(\"v.shape:\", v.shape)\n",
        "print(\"padding_mask.shape:\", padding_mask.shape)\n",
        "\n",
        "output, attention_weights = mha(v, k, q, mask)\n",
        "print(\"output.shape:\", output.shape)\n",
        "print(\"attention_weights.shape:\", attention_weights.shape)\n",
        "\n",
        "print(\"\\noutput:\", output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A216_jx4gBKL"
      },
      "source": [
        "## Position-wise Feed-Forward Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGrLRAgjgCqZ"
      },
      "source": [
        "# 建立 Transformer 裡 Encoder / Decoder layer 都有使用到的 Feed Forward 元件\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  \n",
        "  # 此 FFN 對輸入做兩個線性轉換，中間加了一個 ReLU activation func\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHiUmmdxgIZx"
      },
      "source": [
        "### 建立一個 FFN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf1LpEOQgJV8",
        "outputId": "2434e6dd-24f9-4f8e-e4a2-b08dfaa39d79"
      },
      "source": [
        "batch_size = 64\n",
        "seq_len = 10\n",
        "d_model = 512\n",
        "dff = 2048\n",
        "\n",
        "x = tf.random.uniform((batch_size, seq_len, d_model))\n",
        "ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "out = ffn(x)\n",
        "print(\"x.shape:\", x.shape)\n",
        "print(\"out.shape:\", out.shape)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape: (64, 10, 512)\n",
            "out.shape: (64, 10, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6JR_8CIgOIN",
        "outputId": "36f52e6c-4e85-4abb-fb18-d1ea46fbcd20"
      },
      "source": [
        "d_model = 4 # FFN 的輸入輸出張量的最後一維皆為 `d_model`\n",
        "dff = 6\n",
        "\n",
        "# 建立一個小 FFN\n",
        "small_ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "# 懂子詞梗的站出來\n",
        "dummy_sentence = tf.constant([[5, 5, 6, 6], \n",
        "                              [5, 5, 6, 6], \n",
        "                              [9, 5, 2, 7], \n",
        "                              [9, 5, 2, 7],\n",
        "                              [9, 5, 2, 7]], dtype=tf.float32)\n",
        "small_ffn(dummy_sentence)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
              "       [ 2.8674245 , -2.174698  , -1.3073453 , -6.4233937 ],\n",
              "       [ 3.6502066 , -0.97325814, -2.412656  , -6.509499  ],\n",
              "       [ 3.6502066 , -0.97325814, -2.412656  , -6.509499  ],\n",
              "       [ 3.6502066 , -0.97325814, -2.412656  , -6.509499  ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWPtLWY_gR_F"
      },
      "source": [
        "# Encoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Y2JDm2gUPo"
      },
      "source": [
        "# Encoder 裡頭會有 N 個 EncoderLayers，而每個 EncoderLayer 裡又有兩個 sub-layers: MHA & FFN\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  # Transformer 論文內預設 dropout rate 為 0.1\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    # layer norm 很常在 RNN-based 的模型被使用。一個 sub-layer 一個 layer norm\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    # 一樣，一個 sub-layer 一個 dropout layer\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  # 需要丟入 `training` 參數是因為 dropout 在訓練以及測試的行為有所不同\n",
        "  def call(self, x, training, mask):\n",
        "    # 除了 `attn`，其他張量的 shape 皆為 (batch_size, input_seq_len, d_model)\n",
        "    # attn.shape == (batch_size, num_heads, input_seq_len, input_seq_len)\n",
        "    \n",
        "    # sub-layer 1: MHA\n",
        "    # Encoder 利用注意機制關注自己當前的序列，因此 v, k, q 全部都是自己\n",
        "    # 另外別忘了我們還需要 padding mask 來遮住輸入序列中的 <pad> token\n",
        "    attn_output, attn = self.mha(x, x, x, mask)  \n",
        "    attn_output = self.dropout1(attn_output, training=training) \n",
        "    out1 = self.layernorm1(x + attn_output)  \n",
        "    \n",
        "    # sub-layer 2: FFN\n",
        "    ffn_output = self.ffn(out1) \n",
        "    ffn_output = self.dropout2(ffn_output, training=training)  # 記得 training\n",
        "    out2 = self.layernorm2(out1 + ffn_output)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTMPy3ujgcxJ"
      },
      "source": [
        "# 之後可以調的超參數。這邊為了 demo 設小一點\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "\n",
        "# 新建一個使用上述參數的 Encoder Layer\n",
        "enc_layer = EncoderLayer(d_model, num_heads, dff)\n",
        "padding_mask = create_padding_mask(inp)  # 建立一個當前輸入 batch 使用的 padding mask\n",
        "enc_out = enc_layer(emb_inp, training=False, mask=padding_mask)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"padding_mask:\", padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"emb_inp:\", emb_inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "assert emb_inp.shape == enc_out.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU1H0OItgi3y"
      },
      "source": [
        "# Decoder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzBxk-e_gigT"
      },
      "source": [
        "# Decoder 裡頭會有 N 個 DecoderLayer，\n",
        "# 而 DecoderLayer 又有三個 sub-layers: 自注意的 MHA, 關注 Encoder 輸出的 MHA & FFN\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    # 3 個 sub-layers 的主角們\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    # 定義每個 sub-layer 用的 LayerNorm\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    # 定義每個 sub-layer 用的 Dropout\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           combined_mask, inp_padding_mask):\n",
        "    # 所有 sub-layers 的主要輸出皆為 (batch_size, target_seq_len, d_model)\n",
        "    # enc_output 為 Encoder 輸出序列，shape 為 (batch_size, input_seq_len, d_model)\n",
        "    # attn_weights_block_1 則為 (batch_size, num_heads, target_seq_len, target_seq_len)\n",
        "    # attn_weights_block_2 則為 (batch_size, num_heads, target_seq_len, input_seq_len)\n",
        "\n",
        "    # sub-layer 1: Decoder layer 自己對輸出序列做注意力。\n",
        "    # 我們同時需要 look ahead mask 以及輸出序列的 padding mask \n",
        "    # 來避免前面已生成的子詞關注到未來的子詞以及 <pad>\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, combined_mask)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    # sub-layer 2: Decoder layer 關注 Encoder 的最後輸出\n",
        "    # 記得我們一樣需要對 Encoder 的輸出套用 padding mask 避免關注到 <pad>\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, inp_padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    # sub-layer 3: FFN 部分跟 Encoder layer 完全一樣\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    # 除了主要輸出 `out3` 以外，輸出 multi-head 注意權重方便之後理解模型內部狀況\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWUhornggqt_"
      },
      "source": [
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"tar_padding_mask:\", tar_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"look_ahead_mask:\", look_ahead_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asAN1fmGgwy1"
      },
      "source": [
        "把中文（目標語言）的詞嵌入張量以及相關的遮罩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro4BgfkfgxT-"
      },
      "source": [
        "# 超參數\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "dec_layer = DecoderLayer(d_model, num_heads, dff)\n",
        "\n",
        "# 來源、目標語言的序列都需要 padding mask\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "\n",
        "# masked MHA 用的遮罩，把 padding 跟未來子詞都蓋住\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[-1])\n",
        "combined_mask = tf.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 實際初始一個 decoder layer 並做 3 個 sub-layers 的計算\n",
        "dec_out, dec_self_attn_weights, dec_enc_attn_weights = dec_layer(\n",
        "    emb_tar, enc_out, False, combined_mask, inp_padding_mask)\n",
        "\n",
        "print(\"emb_tar:\", emb_tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_out:\", dec_out)\n",
        "assert emb_tar.shape == dec_out.shape\n",
        "print(\"-\" * 20)\n",
        "print(\"dec_self_attn_weights.shape:\", dec_self_attn_weights.shape)\n",
        "print(\"dec_enc_attn_weights:\", dec_enc_attn_weights.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6RQsa1Xg7bw"
      },
      "source": [
        "# Positional encoding：神奇數字"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt0QnaXmg85h",
        "outputId": "1c08759b-2538-4b38-9908-ac23fa464381"
      },
      "source": [
        "# 以下直接參考 TensorFlow 官方 tutorial \n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  sines = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  cosines = np.cos(angle_rads[:, 1::2])\n",
        "  \n",
        "  pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
        "  \n",
        "  pos_encoding = pos_encoding[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "seq_len = 50\n",
        "d_model = 512\n",
        "\n",
        "pos_encoding = positional_encoding(seq_len, d_model)\n",
        "pos_encoding"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 50, 512), dtype=float32, numpy=\n",
              "array([[[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
              "          1.        ,  1.        ],\n",
              "        ...,\n",
              "        [ 0.12357312,  0.97718984, -0.24295525, ...,  0.9999863 ,\n",
              "          0.99998724,  0.99998814],\n",
              "        [-0.76825464,  0.7312359 ,  0.63279754, ...,  0.9999857 ,\n",
              "          0.9999867 ,  0.9999876 ],\n",
              "        [-0.95375264, -0.14402692,  0.99899054, ...,  0.9999851 ,\n",
              "          0.9999861 ,  0.9999871 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "OLMeuDndhCJ5",
        "outputId": "41eedab7-09ff-4a90-f0a6-666cf11586d0"
      },
      "source": [
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('d_model')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBgWwJ3-hP6N"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3dgAuAVhSlv"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  # Encoder 的初始參數除了本來就要給 EncoderLayer 的參數還多了：\n",
        "  # - num_layers: 決定要有幾個 EncoderLayers, 前面影片中的 `N`\n",
        "  # - input_vocab_size: 用來把索引轉成詞嵌入向量\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(input_vocab_size, self.d_model)\n",
        "    \n",
        "    # 建立 `num_layers` 個 EncoderLayers\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "    # 輸入的 x.shape == (batch_size, input_seq_len)\n",
        "    # 以下各 layer 的輸出皆為 (batch_size, input_seq_len, d_model)\n",
        "    input_seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # 將 2 維的索引序列轉成 3 維的詞嵌入張量，並依照論文乘上 sqrt(d_model)\n",
        "    # 再加上對應長度的位置編碼\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :input_seq_len, :]\n",
        "\n",
        "    # 對 embedding 跟位置編碼的總合做 regularization\n",
        "    # 這在 Decoder 也會做\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    # 通過 N 個 EncoderLayer 做編碼\n",
        "    for i, enc_layer in enumerate(self.enc_layers):\n",
        "      x = enc_layer(x, training, mask)\n",
        "      # 以下只是用來 demo EncoderLayer outputs\n",
        "      #print('-' * 20)\n",
        "      #print(f\"EncoderLayer {i + 1}'s output:\", x)\n",
        "      \n",
        "    \n",
        "    return x "
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvETaQp0iXDQ"
      },
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Encoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "input_vocab_size = subword_encoder_en.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 初始化一個 Encoder\n",
        "encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列丟入 Encoder 做編碼\n",
        "enc_out = encoder(inp, training=False, mask=None)\n",
        "print(\"inp:\", inp)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9KmTsvLiekt"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQBf2lQqiflw"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  # 初始參數跟 Encoder 只差在用 `target_vocab_size` 而非 `inp_vocab_size`\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, \n",
        "               rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    # 為中文（目標語言）建立詞嵌入層\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(target_vocab_size, self.d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "  \n",
        "  # 呼叫時的參數跟 DecoderLayer 一模一樣\n",
        "  def call(self, x, enc_output, training, \n",
        "           combined_mask, inp_padding_mask):\n",
        "    \n",
        "    tar_seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}  # 用來存放每個 Decoder layer 的注意權重\n",
        "    \n",
        "    # 這邊跟 Encoder 做的事情完全一樣\n",
        "    x = self.embedding(x)  # (batch_size, tar_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :tar_seq_len, :]\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    \n",
        "    for i, dec_layer in enumerate(self.dec_layers):\n",
        "      x, block1, block2 = dec_layer(x, enc_output, training,\n",
        "                                    combined_mask, inp_padding_mask)\n",
        "      \n",
        "      # 將從每個 Decoder layer 取得的注意權重全部存下來回傳，方便我們觀察\n",
        "      attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, tar_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKl6RVLEitwJ"
      },
      "source": [
        "# 超參數\n",
        "num_layers = 2 # 2 層的 Decoder\n",
        "d_model = 4\n",
        "num_heads = 2\n",
        "dff = 8\n",
        "target_vocab_size = subword_encoder_zh.vocab_size + 2 # 記得加上 <start>, <end>\n",
        "\n",
        "# 遮罩\n",
        "inp_padding_mask = create_padding_mask(inp)\n",
        "tar_padding_mask = create_padding_mask(tar)\n",
        "look_ahead_mask = create_look_ahead_mask(tar.shape[1])\n",
        "combined_mask = tf.math.maximum(tar_padding_mask, look_ahead_mask)\n",
        "\n",
        "# 初始化一個 Decoder\n",
        "decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size)\n",
        "\n",
        "# 將 2 維的索引序列以及遮罩丟入 Decoder\n",
        "print(\"tar:\", tar)\n",
        "print(\"-\" * 20)\n",
        "print(\"combined_mask:\", combined_mask)\n",
        "print(\"-\" * 20)\n",
        "print(\"enc_out:\", enc_out)\n",
        "print(\"-\" * 20)\n",
        "print(\"inp_padding_mask:\", inp_padding_mask)\n",
        "print(\"-\" * 20)\n",
        "dec_out, attn = decoder(tar, enc_out, training=False, \n",
        "                        combined_mask=combined_mask,\n",
        "                        inp_padding_mask=inp_padding_mask)\n",
        "print(\"dec_out:\", dec_out)\n",
        "print(\"-\" * 20)\n",
        "for block_name, attn_weights in attn.items():\n",
        "  print(f\"{block_name}.shape: {attn_weights.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4WPfQati2j-"
      },
      "source": [
        "# Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VJ7uUxhi3g7"
      },
      "source": [
        "# Transformer 之上已經沒有其他 layers 了，我們使用 tf.keras.Model 建立一個模型\n",
        "class Transformer(tf.keras.Model):\n",
        "  # 初始參數包含 Encoder & Decoder 都需要超參數以及中英字典數目\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, rate)\n",
        "    # 這個 FFN 輸出跟中文字典一樣大的 logits 數，等通過 softmax 就代表每個中文字的出現機率\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "  \n",
        "  # enc_padding_mask 跟 dec_padding_mask 都是英文序列的 padding mask，\n",
        "  # 只是一個給 Encoder layer 的 MHA 用，一個是給 Decoder layer 的 MHA 2 使用\n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           combined_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, combined_mask, dec_padding_mask)\n",
        "    \n",
        "    # 將 Decoder 輸出通過最後一個 linear layer\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": 111,
      "outputs": []
    }
  ]
}